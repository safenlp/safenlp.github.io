---
page-layout: full
---
<div class="gradient-text">

<div class="welcome-headline">
SafeNLP: Trustworthy AI Through Rigorous Safety<br>
</div>
<div class="welcome-subheadline">
Safety solutions and research for NLP, LLM, and AI
</div>
</div>

::::{.cmm-background}
::: {.content-container}
::: {.welcome }


::: grid
::: {.g-col-12 .g-col-lg-4 .welcome-text .sand-background style="padding: 15px;"}

We explore safety solutions and research for **NLP, LLM, and AI**, designing approaches for both academic and industry levels with emphasis on **security and ethical principles**. Our work spans bias detection and mitigation, privacy-preserving techniques, adversarial robustness, content moderation, transparency, and comprehensive safety benchmarking for language models.

[GitHub](https://github.com/safenlp) | [LinkedIn](https://www.linkedin.com/company/safenlp)
:::

:::



:::
:::
::::

